{
  "title": "Nov 11: Meeting with Chang",
  "cells": [
    {
      "type": "text",
      "data": "<div style=\"word-wrap: break-word; -webkit-nbsp-mode: space; -webkit-line-break: after-white-space; white-space: normal;\"><div>TLDR; Idea feasible, might want to consider pretraining to match the bourgain latent space and the bottleneck of the network, but depends on the application</div><div><br /></div><div><br /></div><ul><li><div>Idea is feasible</div></li><li><div>They pretrained to match the distribution of the latent space and the output space, but this might not be necessary for my application. (This is basically preserving the location of clusters in the bourgain latent space and that of the output space. This is NOT encoded in the second term in the loss function.)</div></li><li><div>The second term in the loss function in the GANS could be used for the classification loss — you wanna preserve the pairwise distances so that you can go back and add stuff to the embedding space. (This is DIFFERENT from the first point, and means to preserve pairwise distances when training the network.)</div></li><li><div>Pretraining would match the position of clusters in the bourgain space with that of the embedding space — could potentially save time when recalling the position of clusters when creating a new cluster in the embedding space. (Need to think more about this)</div></li><li><div>Chang also mentioned entering the precomputed bourgain embeddings of images as inputs to the network. But such embeddings aren’t learnt, and don’t contain information that allows successful classification, so reasoning on the input-bourgain level (interpolating between different clusters) might not help much with classification. Worth trying as a baseline though.</div></li><li><div>The distance metric that they used was the “classifier distance”. I’d like to use something similar for my experiments, before human-defined distances. First show that better learning of new classes can be done on simple (MNIST) datasets, and on nicely defined distance functions before moving onto human-defined distance functions and more complicated datasets.</div></li></ul><div><br /></div><div><img src='quiver-image-url/0219D6A6CDD49332B230C93EAEC788C3.jpg' title='Attachment'><br /></div><div><br /></div></div>"
    }
  ]
}