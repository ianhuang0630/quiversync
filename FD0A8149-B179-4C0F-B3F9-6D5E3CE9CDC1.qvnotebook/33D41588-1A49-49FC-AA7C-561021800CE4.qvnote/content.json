{
  "title": "July 22: {N} Pretraining tree encoder considerations",
  "cells": [
    {
      "type": "markdown",
      "data": "## the intersection between imagenet (upon which resnet, the feature extractor is trained) and classes in EPIC KITCHEN\n\nClasses in imagenet:\nhttps://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57\n\n"
    },
    {
      "type": "markdown",
      "data": "new ones\nrun 5: rescaling\nrun 6: blackout\n\nrun 7: running with only 2 classes, 200 pairwise clip samples. lr adjusted to be 0.01 (faster end). Expected to overfit. (doesn't seem to be overfitting)\n\nrun 8: runnign with 2 classes, 20 pairwise clip samples.  using RESNET as a feature extractor.\nrun 9: running with 2 classes, 20 pairwise clip samples, with sam elearning rate as run 8 (0.0001). Done **without** a feature extractor.\n\nrun 8 shows slower convergence than run 9 -- suggests that resnet is actually making it harder to overfit. This may because different images become very close in the output feature space.\n\nrun 10: 200 pairwise samples.\n\n"
    }
  ]
}